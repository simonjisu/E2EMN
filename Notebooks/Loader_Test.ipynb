{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from copy import deepcopy\n",
    "import random\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bAbI_data_loader(path, vocab=None):\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            data = file.readlines()\n",
    "        data = [l.strip() for l in data]\n",
    "    except:\n",
    "        print('no such file: {}'.format(path))\n",
    "        return None\n",
    "\n",
    "    data_temp = []\n",
    "    story = []\n",
    "    \n",
    "    try:\n",
    "        for line in data:\n",
    "            idx, line = line.split(' ', 1)\n",
    "            if idx == '1':\n",
    "                story = []\n",
    "\n",
    "            if '?' in line:\n",
    "                q, a, support = line.split('\\t')\n",
    "                q = q.lower().strip().replace('?', '').split() + ['?']\n",
    "                a = a.lower().strip().split() + ['</s>']\n",
    "                support = int(support)\n",
    "                story_temp = deepcopy(story)\n",
    "                data_temp.append([story_temp, q, a, support])\n",
    "            else:\n",
    "                sentence = line.lower().replace('.', '').split() + ['</s>']\n",
    "                story.append(sentence)\n",
    "\n",
    "    except:\n",
    "        print('check data')\n",
    "        return None\n",
    "\n",
    "    if vocab:\n",
    "        data, vocab = bAbI_build_vocab(data_temp, vocab)\n",
    "    else:\n",
    "        data, vocab = bAbI_build_vocab(data_temp)\n",
    "    \n",
    "    return data, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bAbI_build_vocab(data, vocab=None):\n",
    "    if vocab is None:\n",
    "        story, q, a, s = list(zip(*data))\n",
    "        vocab = list(set(flatten(flatten(story)) + flatten(q) + flatten(a)))\n",
    "        word2idx = {'<pad>': 0, '<unk>': 1, '<s>': 2, '</s>': 3}\n",
    "        for word in vocab:\n",
    "            if word2idx.get(word) is None:\n",
    "                word2idx[word] = len(word2idx)\n",
    "        idx2word = {v: k for k, v in word2idx.items()}\n",
    "    else:\n",
    "        word2idx = vocab\n",
    "    \n",
    "    for d in data:\n",
    "        # d[0]: stories\n",
    "        # d[1]: questions\n",
    "        # d[2]: answer\n",
    "        # d[3]: support\n",
    "        for i, story in enumerate(d[0]):\n",
    "            d[0][i] = transfer2idx(story, word2idx)\n",
    "            \n",
    "        d[1] = transfer2idx(d[1], word2idx)\n",
    "        d[2] = transfer2idx(d[2], word2idx)\n",
    "    \n",
    "    return data, word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer2idx(seq, dictionary):\n",
    "    idxs = list(map(lambda w: dictionary[w] if dictionary.get(w) is not None else \\\n",
    "                    dictionary[\"<unk>\"], seq))\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_loader(train_data, batch_size, shuffle=False):\n",
    "    if shuffle: random.shuffle(train_data)\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex: eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_to_batch(batch, w2idx):\n",
    "    \"\"\"\n",
    "    stories, stories_masks: B, n, T_c\n",
    "    questions, questions_masks: B, T_q\n",
    "    answers: B, T_a\n",
    "    supports: B\n",
    "    \"\"\"\n",
    "    story, q, a, s = list(zip(*batch))\n",
    "    max_story = max([len(s) for s in story]) # max_stories\n",
    "    max_len = max([len(s) for s in flatten(story)]) # max_sentence_len\n",
    "    max_q = max([len(q_) for q_ in q])\n",
    "    max_a = max([len(a_) for a_ in a])\n",
    "\n",
    "    stories, stories_masks = [], []\n",
    "    for i in range(len(batch)):\n",
    "        story_array, story_mask = get_batch_array(get_fixed_array(story[i], w2idx), max_story, max_len)\n",
    "        stories.append(story_array)\n",
    "        stories_masks.append(story_mask)\n",
    "        \n",
    "    questions, questions_masks = get_batch_array(get_fixed_array(q, w2idx), len(batch), max_q)\n",
    "    answers, _ = get_batch_array(get_fixed_array(a, w2idx), len(batch), max_a)\n",
    "    \n",
    "    return trans2tensor(stories), trans2tensor(stories_masks), trans2tensor(questions), \\\n",
    "            trans2tensor(questions_masks), trans2tensor(answers), list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fixed_array(data, w2idx):\n",
    "    max_col = max([len(d) for d in data])\n",
    "    for j in range(len(data)):\n",
    "        if len(data[j]) < max_col:\n",
    "            data[j].append(w2idx.get('<pad>'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_array(data, *shape):\n",
    "    r, c = shape\n",
    "    temp = np.zeros((r, c), dtype=np.int)\n",
    "    it = np.nditer(np.array(data, dtype=np.int), flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = np.array(data)[idx]\n",
    "        temp[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    mask = (temp == 0).astype(np.byte)\n",
    "    return temp.tolist(), mask.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans2tensor(x):\n",
    "    return Variable(torch.LongTensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../data/QA_bAbI_tasks/en-10k/qa1_single-supporting-fact_train.txt'\n",
    "data, word2idx = bAbI_data_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "for batch in data_loader(data, batch_size, shuffle=False):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stories, stories_masks, questions, questions_masks, answers, supports = pad_to_batch(batch, word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 7])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_masks.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_masks.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
