{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-1]))\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from model.bAbI_utils_loader import bAbIDataset, bAbIDataLoader\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = 0 if USE_CUDA else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./figs/E2EMN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer\n",
    "Sentences: \n",
    "\n",
    "$$X = [x_1, x_2, \\cdots, x_n]: n \\times T_c$$\n",
    "\n",
    "* $n$: number of sentences in context\n",
    "* $T_c$: max length of a sentence in context\n",
    "\n",
    "Embeding Matrix: \n",
    "\n",
    "$$\\begin{aligned}\n",
    "A &: d \\times V \\\\\n",
    "B &: d \\times V \\\\\n",
    "C &: d \\times V\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "m_i &= \\sum_j Ax_{ij}: T_c \\times d \\\\ \n",
    "c_i &= \\sum_j Cx_{ij}: T_c \\times d\\\\\n",
    "u &= \\sum_j Bq_{j}: T_q \\times d\n",
    "\\end{aligned}$$\n",
    "\n",
    "total embedding of context: $M : n \\times T_c \\times d$\n",
    "* $m_i(c_i)$: summation embedded for each sentence in context as length of $T_c$, $n \\times d$\n",
    "* $u$: summation embedded for query(question) as length of $T_q$, $1 \\times d$\n",
    "* $score = m_iu^T: (n \\times d) \\cdot (d \\times 1) = n \\times 1$\n",
    "\n",
    "attention:\n",
    "$$\\begin{aligned}\n",
    "p_i &= softmax(score): n \\times 1 \\\\\n",
    "o &= \\sum_i c_i p_i : d \\times 1 \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "summation vectors to linear layer:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "inputs &= u + o : d \\times 1 \\\\\n",
    "a &= softmax(W \\cdot inputs) : (V \\times d) \\times (d \\times 1) = V \\times 1\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1503.08895.pdf\n",
    "\n",
    "https://github.com/nmhkahn/MemN2N-pytorch/blob/master/memn2n/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "postion encoding(PE):\n",
    "\n",
    "$$\\begin{aligned}\n",
    "m_i &= \\sum_j l_j \\otimes Ax_{ij}: T_c \\times d \\\\ \n",
    "l_{kj} &= (1-\\frac{j}{J}) - (\\frac{k}{d})(1-\\frac{2j}{J})\n",
    "\\end{aligned}$$\n",
    "\n",
    "* $J$: number of word in sentences\n",
    "* $d$: dimension of embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class E2EMN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, n_hops=3, encoding_method=['basic'], use_cuda=False):\n",
    "        super(E2EMN, self).__init__()\n",
    "        assert isinstance(encoding_method, list), 'encoding_method must be a list type'\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.n_hops = n_hops\n",
    "        self.encoding_method = [e.lower() for e in encoding_method]\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        \n",
    "        # sharing matrix for k hops & and init to normal dist.\n",
    "        self.embed_A = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.embed_B = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.embed_C = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "    \n",
    "        self.linear = nn.Linear(embed_size, vocab_size)\n",
    "    \n",
    "    def _weigth_init(self):\n",
    "        pass\n",
    "    \n",
    "    def _temporal_encoding_requirements(self, story_len):\n",
    "        # temporal encoding\n",
    "        if 'temp' in self.encoding_method:\n",
    "            assert story_len is not None, 'must have a fixed story_len, insert \"story_len\" as a number'\n",
    "            assert isinstance(story_len, int), '\"story_len\" must be a integer'\n",
    "            \n",
    "            self.embed_A_T = nn.Embedding(story_len, embed_size)\n",
    "            self.embed_C_T = nn.Embedding(story_len, embed_size)\n",
    "        else:\n",
    "            self.embed_A_T = None\n",
    "            self.embed_C_T = None\n",
    "            \n",
    "    def _pe_requirements(self, stories_masks):\n",
    "        if stories_masks is not None:\n",
    "            pe_word_lengths = stories_masks.eq(0).sum(2) #B, n : byte tensor\n",
    "        else:\n",
    "            pe_word_lengths = None\n",
    "        return pe_word_lengths\n",
    "    \n",
    "    def encoding2memory(self, embeded_x, word_length=None):\n",
    "        \"\"\"\n",
    "        embed_x: n, T_c, d\n",
    "        word_length: n\n",
    "        \"\"\"\n",
    "        if (len(self.encoding_method) == 1) and self.encoding_method[0] == 'basic':\n",
    "            return embeded_x.sum(1) # n, d\n",
    "        \n",
    "        if 'pe' in self.encoding_method:\n",
    "            assert word_length is not None, 'insert stories_masks when forward'\n",
    "            \n",
    "            T_c, d = embeded_x.size()[1:]\n",
    "            j = Variable(torch.arange(1, T_c+1).unsqueeze(1).repeat(1, d), requires_grad=False)\n",
    "            k = Variable(torch.arange(1, d+1).unsqueeze(1).repeat(1, T_c).t(), requires_grad=False)\n",
    "            if self.use_cuda:\n",
    "                    j, k = j.cuda(), k.cuda()\n",
    "                    \n",
    "            embeded_x_pe = []\n",
    "            for embed, J in zip(embeded_x, word_length.float()): # iteration of n size\n",
    "                if J.eq(0).data[0]: # all pad data which word length = 0\n",
    "                    embeded_x_pe.append(embed)\n",
    "                else:\n",
    "                    l = (torch.ones_like(embed).float() - j/J) - (k/d)*(torch.ones_like(embed) - (2*j)/J)\n",
    "                    embed = embed * l\n",
    "                    embeded_x_pe.append(embed) # T_c, d\n",
    "            embeded_x_pe = torch.stack(embeded_x_pe) # n, T_c, d\n",
    "            return embeded_x_pe.sum(1) # n, d\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, stories, questions, stories_masks=None, questions_masks=None, story_len=None):\n",
    "        \"\"\"\n",
    "        stories, stories_masks: B, n, T_c\n",
    "        questions, questions_masks: B, T_q\n",
    "        \"\"\"\n",
    "        # init some requirements\n",
    "        self._temporal_encoding_requirements(story_len)\n",
    "        pe_word_lengths = self._pe_requirements(stories_masks)\n",
    "        \n",
    "        # Start Learning\n",
    "        o_list = []\n",
    "        # questions: B, T_q\n",
    "        embeded_B = self.embed_B(questions) # B, T_q, d\n",
    "        u = embeded_B.sum(1) # u: B, d\n",
    "        o_list.append(u) # [(B, d)]\n",
    "        \n",
    "        for k in range(self.n_hops):\n",
    "            batch_memories = [] # B, n, d\n",
    "            batch_contexts = [] # B, n, d\n",
    "            for i, inputs in enumerate(stories): # iteration of batch\n",
    "                # inputs: n, T_c\n",
    "                embeded_A = self.embed_A(inputs) # n, T_c, d\n",
    "                embeded_C = self.embed_C(inputs)\n",
    "\n",
    "                m = self.encoding2memory(embeded_A, pe_word_lengths[i]) # n, d\n",
    "                c = self.encoding2memory(embeded_C, pe_word_lengths[i])\n",
    "                \n",
    "                batch_memories.append(m)\n",
    "                batch_contexts.append(c)\n",
    "\n",
    "            batch_memories = torch.stack(batch_memories) # B, n, d\n",
    "            batch_contexts = torch.stack(batch_contexts) # B, n, d\n",
    "\n",
    "            # attention: select which sentence to attent\n",
    "            # score = m * u[-1] : (B, n, d) * (B, d, 1) = B, n, 1\n",
    "            score = torch.bmm(batch_memories, o_list[-1].unsqueeze(2)) \n",
    "            probs = F.softmax(score, dim=1) # p: B, n, 1\n",
    "\n",
    "            # output: element-wies mul & sum (B, n, d) x (B, n, 1) = B, n, d > B, d\n",
    "            o = torch.sum(batch_contexts * probs, 1)\n",
    "\n",
    "            o_next = o_list[-1] + o\n",
    "            o_list.append(o_next) # B, d\n",
    "\n",
    "        outputs = self.linear(o_list[-1]) # B, d > B, V\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings: Train_loader & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_train = '../data/QA_bAbI_tasks/en-10k/qa1_single-supporting-fact_train.txt'\n",
    "bAbI_train = bAbIDataset(path_train, train=True, return_masks=True)\n",
    "train_loader = bAbIDataLoader(dataset=bAbI_train, batch_size=32, shuffle=True, to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(bAbI_train.word2idx)\n",
    "EMBED_SIZE = 50\n",
    "N_HOPS = 3\n",
    "LR = 0.01\n",
    "STEP = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings: Loss Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = E2EMN(VOCAB_SIZE, EMBED_SIZE, n_hops=N_HOPS, encoding_method=['pe'])\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "    \n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(gamma=0.5, milestones=[25, 50, 75], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cuda(*args):\n",
    "    return [x.cuda() for x in args]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-71aee5ac63fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstories_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstories_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-eb7202e7968e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, stories, questions, stories_masks, questions_masks)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0membeded_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding2memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeded_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpe_word_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# n, d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding2memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeded_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpe_word_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mbatch_memories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-eb7202e7968e>\u001b[0m in \u001b[0;36mencoding2memory\u001b[0;34m(self, embeded_x, word_length)\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0membeded_x_pe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                     \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0membeded_x_pe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# T_c, d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for step in range(STEP):\n",
    "    losses=[]\n",
    "    scheduler.step()\n",
    "    for i, batch in enumerate(train_loader.load()):\n",
    "        stories, stories_masks, questions, _, answers, _ = batch\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            stories, stories_masks, questions, answers = get_cuda(stories, stories_masks, questions, answers)\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        preds = model.forward(stories, questions, stories_masks=stories_masks)\n",
    "        \n",
    "        loss = loss_function(preds, answers.view(-1))\n",
    "        losses.append(loss.data[0])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (step+1) % 10 == 0:\n",
    "        string = '[{}/{}] loss: {:.4f}, lr: {}'.format(step+1, STEP, np.mean(losses), scheduler.get_lr()[0])\n",
    "        print(string)\n",
    "        losses=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_test = '../data/QA_bAbI_tasks/en-10k/qa1_single-supporting-fact_test.txt'\n",
    "bAbI_test = bAbIDataset(path_test, train=False, vocab=bAbI_train.word2idx, return_masks=False)\n",
    "test_loader = bAbIDataLoader(dataset=bAbI_test, batch_size=32, shuffle=True, to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.599\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy = 0\n",
    "for i, batch in enumerate(test_loader.load()):\n",
    "    stories, questions, answers, _ = batch\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        stories = [get_cuda(x) for x in stories]\n",
    "        questions, answers = get_cuda(questions, answers)\n",
    "        \n",
    "    for story, q, a in zip(stories, questions, answers):\n",
    "        model.zero_grad()\n",
    "        pred = model(story.unsqueeze(0), q.unsqueeze(0))\n",
    "        accuracy += torch.eq(torch.max(pred, 1)[1], a).data[0]\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy/len(bAbI_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: random print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w2idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ea74224e47bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbAbI_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_story\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbAbI_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w2idx' is not defined"
     ]
    }
   ],
   "source": [
    "story, q, a, s = bAbI_test.pad_to_story([random.choice(bAbI_test.data)], w2idx)\n",
    "model.zero_grad()\n",
    "pred = model(story[0].unsqueeze(0), q)\n",
    "pred_a = torch.max(pred, 1)[1]\n",
    "\n",
    "print(\"Facts : \")\n",
    "print('-'*45)\n",
    "print('\\n'.join([' '.join(list(map(lambda x: idx2w[x], f))) for f in story[0].data.tolist()]))\n",
    "print('-'*45)\n",
    "print(\"Question : \",' '.join(list(map(lambda x: idx2w[x], q.data.tolist()[0]))))\n",
    "print('-'*45)\n",
    "print(\"Answer : \",' '.join(list(map(lambda x: idx2w[x], a.squeeze(1).data.tolist()))))\n",
    "print(\"Prediction : \",' '.join(list(map(lambda x: idx2w[x], pred_a.data.tolist()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_train = '../data/QA_bAbI_tasks/en-10k/qa1_single-supporting-fact_train.txt'\n",
    "bAbI_train = bAbIDataset(path_train, train=True, return_masks=True)\n",
    "train_loader = bAbIDataLoader(dataset=bAbI_train, batch_size=32, shuffle=True, to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader.load()):\n",
    "    stories, stories_masks, questions, questions_masks, answers, _ = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_length = stories_masks.eq(0).sum(2).float()  # J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_length.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_x = model.embed_A(stories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed_x = temp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T_c, d = embed.size()\n",
    "j = Variable(torch.arange(1, T_c+1).unsqueeze(1).repeat(1, d), requires_grad=False)\n",
    "k = Variable(torch.arange(1, d+1).unsqueeze(1).repeat(1, T_c).t(), requires_grad=False)\n",
    "\n",
    "tt = []\n",
    "for i, (embed, J) in enumerate(zip(embed_x, word_length[0])):\n",
    "    if J.eq(0).data[0]: # all pad data\n",
    "        tt.append(embed)\n",
    "    else:\n",
    "        l = (torch.ones_like(embed).float() - j/J) - (k/d)*(torch.ones_like(embed) - (2*j)/J)\n",
    "        embed = embed * l\n",
    "        tt.append(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  7\n",
       " 16\n",
       " 10\n",
       " 14\n",
       " 12\n",
       "  0\n",
       "[torch.LongTensor of size 6]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed_temp = nn.Embedding(n, EMBED_SIZE, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518385717421/work/torch/lib/TH/generic/THTensorMath.c:277",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-40105b691976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membed_temp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/_functions/thnn/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518385717421/work/torch/lib/TH/generic/THTensorMath.c:277"
     ]
    }
   ],
   "source": [
    "embed_temp(stories[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', \n",
       "               0.9967 -1.5335 -0.2404  ...  -0.5641 -0.4126 -0.6967\n",
       "               0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "              -1.1828 -0.8180 -0.6191  ...  -0.5717  0.8391  0.1589\n",
       "                        ...             â‹±             ...          \n",
       "              -0.6489  1.3622  1.0723  ...   1.0169  1.2179 -1.1631\n",
       "               0.0083 -1.2892  0.5822  ...   0.7219 -1.1516  0.1734\n",
       "              -0.2452  1.2055  0.0817  ...   1.1516 -1.6721 -0.0940\n",
       "              [torch.FloatTensor of size 22x50])])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_temp.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(temp_x.size(0)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 5 \n",
       "-2.2702e-01 -2.5431e-02  1.2480e-01 -9.1293e-02  1.0095e-02  3.6205e-02\n",
       " 5.9523e-03 -3.7339e-02 -7.9318e-02  1.0661e-01 -7.0634e-02  4.7868e-02\n",
       " 7.0597e-03  5.0365e-02  6.3651e-02 -1.1283e-01 -9.9317e-03  9.4435e-02\n",
       "-2.4348e-02  7.9932e-02 -2.8611e-02 -3.5126e-02 -1.0483e-02 -2.4387e-02\n",
       "-2.2498e-04 -8.6771e-03 -3.4956e-03  4.8646e-02 -3.2025e-02 -1.3837e-02\n",
       "-3.4523e-03  1.3824e-03  1.9319e-03 -1.8455e-02  1.9208e-02 -3.5778e-03\n",
       "\n",
       "Columns 6 to 11 \n",
       "-1.0558e-01 -1.0705e-01 -6.8083e-02  2.7638e-02  5.5749e-02 -2.7952e-02\n",
       " 1.6787e-02 -5.2203e-02  6.7505e-02  6.5956e-02 -6.8389e-02  1.2085e-01\n",
       "-3.6121e-02  8.4510e-02 -6.3131e-02 -8.0532e-02 -1.6561e-02  3.2549e-02\n",
       "-3.3294e-02  4.0431e-02 -9.3410e-04 -1.8585e-02 -1.0578e-01  8.2174e-02\n",
       " 1.2895e-02 -8.1865e-03 -4.9495e-02  1.2060e-02  3.1218e-02  2.6556e-02\n",
       "-4.6101e-03 -3.7042e-02 -1.7590e-02  2.0497e-03  1.2112e-02  3.0038e-02\n",
       "\n",
       "Columns 12 to 17 \n",
       " 5.6343e-02  2.8727e-02 -3.0791e-03  4.1079e-02 -1.5735e-02 -1.0354e-01\n",
       "-2.5733e-02  4.1742e-02 -3.0778e-02 -4.1784e-02 -3.3890e-02 -6.2830e-02\n",
       "-4.4656e-02 -4.7838e-02 -1.4544e-02  1.1273e-01 -1.2689e-02  4.5311e-02\n",
       " 1.8878e-02 -1.2719e-02  2.9970e-03 -3.2410e-02  4.0103e-02 -7.7144e-02\n",
       "-8.2396e-03 -1.8775e-02  5.1238e-02 -3.1889e-02 -5.5430e-04 -5.0697e-02\n",
       " 3.1963e-02  7.5624e-03 -4.8859e-02  4.9291e-02  1.4718e-02 -7.8531e-03\n",
       "\n",
       "Columns 18 to 23 \n",
       " 5.9401e-02  5.1999e-04 -1.5666e-03 -4.7041e-02 -4.7273e-02  3.8532e-02\n",
       " 1.3801e-01  6.3456e-02 -2.6404e-02  4.5331e-02  3.4098e-02  7.4491e-02\n",
       " 2.1804e-02  3.5214e-02 -8.0357e-03  3.7530e-02  2.0035e-02 -7.5052e-03\n",
       "-7.5876e-04  9.3355e-03 -6.4757e-02  6.1077e-02  8.2495e-02  8.7829e-02\n",
       "-1.0445e-02 -4.0338e-02  1.2266e-02 -4.9847e-02 -5.4223e-02  4.9686e-02\n",
       " 1.0379e-02 -4.9006e-02  2.2220e-02  1.0394e-02 -1.7736e-04 -3.0272e-02\n",
       "\n",
       "Columns 24 to 29 \n",
       " 1.0435e-02 -1.3226e-02 -3.4215e-02  2.9473e-02  3.0125e-02  5.8606e-02\n",
       " 3.4969e-02  6.3033e-02 -4.1911e-03  2.2455e-03 -1.3025e-01  1.3116e-02\n",
       "-1.4864e-02  9.8671e-03  1.4008e-02 -5.9770e-02  2.1879e-02 -3.4215e-02\n",
       " 6.7322e-02  1.7338e-02  1.0311e-01 -3.7647e-02  1.0050e-02  1.0944e-02\n",
       " 3.0060e-02  3.7823e-02  3.1262e-02 -5.0370e-04 -1.2957e-01 -6.4225e-02\n",
       "-3.5176e-02 -4.0441e-02 -8.3749e-02  1.7198e-02  1.0760e-03  6.1636e-03\n",
       "\n",
       "Columns 30 to 35 \n",
       " 7.5261e-02 -1.0992e-02 -1.0737e-02  3.6797e-02  2.0376e-03  8.1859e-03\n",
       " 2.1151e-03  2.8897e-02 -7.5621e-06 -9.4183e-02  3.0888e-02  3.6999e-02\n",
       "-3.8437e-02 -3.2036e-02  7.6508e-03 -4.5204e-06 -3.5947e-03  1.0477e-01\n",
       " 3.3157e-02 -3.0521e-02  4.0100e-03  9.3386e-04  8.7950e-03 -1.0870e-01\n",
       " 5.3258e-02  1.4298e-03 -2.7490e-02 -4.6656e-02  1.6981e-02  1.4777e-02\n",
       "-1.2340e-01 -2.9434e-02  8.6329e-02 -6.1832e-02 -5.6377e-02 -1.5330e-01\n",
       "\n",
       "Columns 36 to 41 \n",
       "-3.2378e-02 -1.4156e-02 -7.6064e-03  4.6921e-02 -1.0875e-03  4.5095e-02\n",
       "-4.6821e-03  1.0197e-03  2.1894e-02 -1.0219e-02 -8.7529e-02 -1.1063e-01\n",
       "-3.7481e-02 -1.6203e-02  3.2141e-02  1.8867e-02 -2.9135e-02 -1.0499e-01\n",
       "-6.7796e-03  7.4738e-02  8.0803e-02 -1.1655e-02  1.5431e-02 -9.0734e-02\n",
       " 3.2761e-02  4.0859e-02 -1.1313e-01  4.0879e-02 -7.3287e-02 -4.8076e-02\n",
       " 1.8514e-02  3.3019e-02  1.0989e-01  1.7629e-02 -5.1196e-02 -7.6245e-05\n",
       "\n",
       "Columns 42 to 47 \n",
       " 2.0386e-02  2.7738e-02 -4.6984e-03  2.1646e-02 -9.3461e-03 -1.1050e-03\n",
       "-3.0223e-02  4.5720e-02 -3.4515e-02  1.0047e-02  3.8754e-02 -2.9036e-03\n",
       " 2.9947e-02 -3.8383e-02 -1.0169e-01  7.5090e-02  4.9458e-02 -3.9925e-02\n",
       "-5.0711e-02 -8.7894e-02 -5.4109e-02 -2.3786e-02  6.9937e-04  2.0197e-02\n",
       " 2.2629e-02 -9.5631e-02  4.1196e-02  5.7317e-02  1.5465e-01  6.4834e-02\n",
       " 1.2860e-02  9.4521e-02  1.6838e-02  7.0525e-02  4.0145e-02 -4.1602e-02\n",
       "\n",
       "Columns 48 to 49 \n",
       " 3.4047e-03 -1.5949e-02\n",
       " 2.5548e-03 -3.6843e-02\n",
       " 3.9448e-02  9.1289e-02\n",
       " 8.6121e-03 -5.1450e-02\n",
       "-6.5733e-02 -8.1338e-02\n",
       " 1.9526e-02 -5.4883e-03\n",
       "[torch.FloatTensor of size 6x50]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
