{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-1]))\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from model.bAbI_utils_loader import bAbIDataset, bAbIDataLoader\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = 0 if USE_CUDA else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./figs/E2EMN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer\n",
    "\n",
    "### Sentences: \n",
    "\n",
    "$$X = [x_1, x_2, \\cdots, x_n]: n \\times T_c$$\n",
    "\n",
    "* $n$: number of sentences in context\n",
    "* $T_c$: max length of a sentence in context\n",
    "\n",
    "### Embeding Matrix: \n",
    "\n",
    "$$\\begin{aligned}\n",
    "A &: d \\times V \\\\\n",
    "B &: d \\times V \\\\\n",
    "C &: d \\times V\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "m_i &= \\sum_j Ax_{ij}: T_c \\times d \\\\ \n",
    "c_i &= \\sum_j Cx_{ij}: T_c \\times d\\\\\n",
    "u &= \\sum_j Bq_{j}: T_q \\times d\n",
    "\\end{aligned}$$\n",
    "\n",
    "total embedding of context: $M : n \\times T_c \\times d$\n",
    "* $m_i(c_i)$: summation embedded for each sentence in context as length of $T_c$, $n \\times d$\n",
    "* $u$: summation embedded for query(question) as length of $T_q$, $1 \\times d$\n",
    "* $score = m_iu^T: (n \\times d) \\cdot (d \\times 1) = n \\times 1$\n",
    "\n",
    "### attention:\n",
    "$$\\begin{aligned}\n",
    "p_i &= softmax(score): n \\times 1 \\\\\n",
    "o &= \\sum_i c_i p_i : d \\times 1 \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "### summation vectors to linear layer:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "inputs &= u + o : d \\times 1 \\\\\n",
    "a &= softmax(W \\cdot inputs) : (V \\times d) \\times (d \\times 1) = V \\times 1\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1503.08895.pdf\n",
    "\n",
    "https://github.com/nmhkahn/MemN2N-pytorch/blob/master/memn2n/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### postion encoding(PE):\n",
    "\n",
    "for each story(sentence) memory $m_i, c_i$\n",
    "$$\\begin{aligned}\n",
    "m_i &= \\sum_j l_j \\otimes Ax_{ij}: T_c \\times d \\\\ \n",
    "l_{jk} &= (1-\\frac{j}{J}) - (\\frac{k}{d})(1-\\frac{2j}{J})\n",
    "\\end{aligned}$$\n",
    "\n",
    "remember, $l_j$ is a matrix that size is $T_c \\times d$\n",
    "\n",
    "* $J$: number of word in sentences\n",
    "* $j$: index of words\n",
    "* $d$: dimension of embedding\n",
    "* $k$: index of embedding dimension\n",
    "\n",
    "### temporal encoding(TE):\n",
    "\n",
    "for each story(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class E2EMN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, n_hops=3, encoding_method='basic', temporal=True, \\\n",
    "                 use_cuda=False, max_story_len=None):\n",
    "        super(E2EMN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.n_hops = n_hops\n",
    "        self.encoding_method = encoding_method.lower()\n",
    "        self.te = temporal\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        # sharing matrix for k hops & and init to normal dist.\n",
    "        self.embed_A = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.embed_B = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.embed_C = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        \n",
    "        # TE: temporal encoding\n",
    "        if self.te:\n",
    "            assert max_story_len is not None, 'must have a fixed story_len, insert \"max_story_len\" as a number'\n",
    "            assert isinstance(max_story_len, int), '\"max_story_len\" must be a integer'\n",
    "            \n",
    "            self.embed_A_T = nn.Embedding(max_story_len+1, self.embed_size, padding_idx=0)\n",
    "            self.embed_C_T = nn.Embedding(max_story_len+1, self.embed_size, padding_idx=0)\n",
    "            if self.use_cuda:\n",
    "                self.embed_A_T = self.embed_A_T.cuda()\n",
    "                self.embed_C_T = self.embed_C_T.cuda()            \n",
    "            \n",
    "        self.linear = nn.Linear(embed_size, vocab_size)\n",
    "        self._weight_init()\n",
    "    \n",
    "    def _weight_init(self):\n",
    "        for x in [self.embed_A, self.embed_B, self.embed_C]:\n",
    "            nn.init.normal(x.weight, mean=0, std=0.1)\n",
    "        if self.te:\n",
    "            for x in [self.embed_A_T, self.embed_C_T]:\n",
    "                nn.init.normal(x.weight, mean=0, std=0.1)\n",
    "    \n",
    "    def _temporal_encoding_requirements(self, stories_masks):\n",
    "        # temporal encoding\n",
    "        if self.te:\n",
    "            story_len = stories_masks.size(1)\n",
    "            temp = stories_masks.eq(0).sum(2) # B, n : byte tensor\n",
    "            te_idx_matrix = Variable(torch.arange(1, story_len+1).repeat(temp.size(0)).view(temp.size()), \\\n",
    "                                     requires_grad=False).long()\n",
    "            if self.use_cuda:\n",
    "                te_idx_matrix = te_idx_matrix.cuda()\n",
    "            te_idx_matrix = te_idx_matrix * temp.ge(1).long() # B, n\n",
    "        else:\n",
    "            te_idx_matrix = None\n",
    "            \n",
    "        return te_idx_matrix\n",
    "\n",
    "            \n",
    "    def _pe_requirements(self, stories_masks):\n",
    "        if stories_masks is not None:\n",
    "            pe_word_lengths = stories_masks.eq(0).sum(2) # B, n : byte tensor\n",
    "        else:\n",
    "            pe_word_lengths = None\n",
    "        return pe_word_lengths\n",
    "    \n",
    "    def encoding2memory(self, embeded_x, word_length=None):\n",
    "        \"\"\"\n",
    "        embed_x: n, T_c, d\n",
    "        word_length: n\n",
    "        \"\"\"\n",
    "        if self.encoding_method == 'basic':\n",
    "            return embeded_x.sum(1) # n, d\n",
    "        \n",
    "        elif self.encoding_method == 'pe':\n",
    "            assert word_length is not None, 'insert stories_masks when forward'\n",
    "            \n",
    "            T_c, d = embeded_x.size()[1:]\n",
    "            j = Variable(torch.arange(1, T_c+1).unsqueeze(1).repeat(1, d), requires_grad=False)\n",
    "            k = Variable(torch.arange(1, d+1).unsqueeze(1).repeat(1, T_c).t(), requires_grad=False)\n",
    "            if self.use_cuda:\n",
    "                j, k = j.cuda(), k.cuda()\n",
    "                    \n",
    "            embeded_x_pe = []\n",
    "            for embed, J in zip(embeded_x, word_length.float()): # iteration of n size\n",
    "                # embed: T_c d\n",
    "                # J: scalar\n",
    "                if J.eq(0).data[0]: # all words are pad data, which means word_length = 0\n",
    "                    embeded_x_pe.append(embed)\n",
    "                else:\n",
    "                    l = (torch.ones_like(embed).float() - j/J) - (k/d)*(torch.ones_like(embed) - (2*j)/J)\n",
    "                    embed = embed * l\n",
    "                    embeded_x_pe.append(embed) # T_c, d\n",
    "            embeded_x_pe = torch.stack(embeded_x_pe) # n, T_c, d\n",
    "            return embeded_x_pe.sum(1) # n, d\n",
    "        \n",
    "        else:\n",
    "            assert True, 'insert encoding_method key value in the model, default is \"basic\".'\n",
    "        \n",
    "    def forward(self, stories, questions, stories_masks=None, questions_masks=None):\n",
    "        \"\"\"\n",
    "        stories, stories_masks: B, n, T_c\n",
    "        questions, questions_masks: B, T_q\n",
    "        \"\"\"\n",
    "        # init some requirements\n",
    "        te_idx_matrix = self._temporal_encoding_requirements(stories_masks)\n",
    "        pe_word_lengths = self._pe_requirements(stories_masks) # B, n \n",
    "        \n",
    "        # Start Learning\n",
    "        o_list = []\n",
    "        # questions: B, T_q\n",
    "        embeded_B = self.embed_B(questions) # B, T_q, d\n",
    "        u = embeded_B.sum(1) # u: B, d\n",
    "        o_list.append(u) # [(B, d)]\n",
    "        \n",
    "        for k in range(self.n_hops):\n",
    "            # encoding part: PE, TE\n",
    "            batch_memories = [] # B, n, d\n",
    "            batch_contexts = [] # B, n, d\n",
    "            for i, inputs in enumerate(stories): # iteration of batch\n",
    "                # inputs: n, T_c\n",
    "                embeded_A = self.embed_A(inputs) # n, T_c, d\n",
    "                embeded_C = self.embed_C(inputs)\n",
    "                # basic or PE\n",
    "                m = self.encoding2memory(embeded_A, pe_word_lengths[i]) # n, d\n",
    "                c = self.encoding2memory(embeded_C, pe_word_lengths[i]) # n, d\n",
    "                # TE\n",
    "                if self.te:\n",
    "                    A_T = self.embed_A_T(te_idx_matrix[i]) # n, d\n",
    "                    C_T = self.embed_C_T(te_idx_matrix[i]) # n, d\n",
    "                    m = m + A_T\n",
    "                    c = c + C_T\n",
    "                batch_memories.append(m)\n",
    "                batch_contexts.append(c)\n",
    "\n",
    "            batch_memories = torch.stack(batch_memories) # B, n, d\n",
    "            batch_contexts = torch.stack(batch_contexts) # B, n, d\n",
    "\n",
    "            # attention part: select which sentence to attent\n",
    "            # score = m * u[-1] : (B, n, d) * (B, d, 1) = B, n, 1\n",
    "            score = torch.bmm(batch_memories, o_list[-1].unsqueeze(2))\n",
    "            probs = F.softmax(score, dim=1) # p: B, n, 1\n",
    "\n",
    "            # output: element-wies mul & sum (B, n, d) x (B, n, 1) = B, n, d > B, d\n",
    "            o = torch.sum(batch_contexts * probs, 1)\n",
    "\n",
    "            o_next = o_list[-1] + o\n",
    "            o_list.append(o_next) # B, d\n",
    "        \n",
    "        # guessing part:\n",
    "        outputs = self.linear(o_list[-1]) # B, d > B, V\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings: Train_loader & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_train = '../data/QA_bAbI_tasks/en-10k/qa1_single-supporting-fact_train.txt'\n",
    "bAbI_train = bAbIDataset(path_train, train=True, return_masks=True)\n",
    "train_loader = bAbIDataLoader(dataset=bAbI_train, batch_size=32, shuffle=True, to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(bAbI_train.word2idx)\n",
    "EMBED_SIZE = 50\n",
    "N_HOPS = 3\n",
    "LR = 0.01\n",
    "STEP = 100\n",
    "MAX_STORY_LEN = bAbI_train.max_story_len\n",
    "BATCH_SIZE = 32\n",
    "EARLY_STOPPING = False\n",
    "# ENCODING_METHOD = 'basic'\n",
    "# TEMPORAL = False\n",
    "ENCODING_METHOD = 'pe'\n",
    "TEMPORAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cuda(*args):\n",
    "    return [x.cuda() for x in args]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings: Loss Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = E2EMN(VOCAB_SIZE, EMBED_SIZE, n_hops=N_HOPS, encoding_method=ENCODING_METHOD, \n",
    "              temporal=TEMPORAL, use_cuda=USE_CUDA, max_story_len=MAX_STORY_LEN)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "    \n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(gamma=0.5, milestones=[25, 50, 75], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] loss: 0.3804, lr: 0.01,\n",
      "[6/100] loss: 0.0000, lr: 0.01,\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for step in range(STEP):\n",
    "    losses=[]\n",
    "    scheduler.step()\n",
    "    if EARLY_STOPPING:\n",
    "        break\n",
    "    for i, batch in enumerate(train_loader.load()):\n",
    "        stories, stories_masks, questions, _, answers, _ = batch\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            stories, stories_masks, questions, answers = get_cuda(stories, stories_masks, questions, answers)\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        preds = model(stories, questions, stories_masks=stories_masks)\n",
    "        \n",
    "        loss = loss_function(preds, answers.view(-1))\n",
    "        losses.append(loss.data[0])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        string = '[{}/{}] loss: {:.4f}, lr: {},'.format(step+1, STEP, np.mean(losses), scheduler.get_lr()[0])\n",
    "        print(string)\n",
    "        if np.mean(losses) < 0.01:\n",
    "            EARLY_STOPPING = True\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "        losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_path = '../model/E2EMN_basic.model'\n",
    "# ENCODING_METHOD = 'basic'\n",
    "# TEMPORAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = '../model/E2EMN_te_pe.model'\n",
    "ENCODING_METHOD = 'pe'\n",
    "TEMPORAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0395 -0.0858  0.0412  ...   0.1262  0.0139  0.0196\n",
       " 0.0534 -0.0255  0.0567  ...  -0.0792 -0.0984  0.0134\n",
       " 0.1134 -0.1136 -0.1169  ...   0.1976  0.2035  0.4299\n",
       "          ...             ⋱             ...          \n",
       " 0.1963 -0.1190  0.2865  ...   0.0464  0.0401 -0.1248\n",
       " 0.0379 -0.1616 -0.0564  ...  -0.0298 -0.0663  0.1711\n",
       "-1.2460 -0.8436 -0.4601  ...   0.9631  0.3113 -0.7624\n",
       "[torch.FloatTensor of size 22x50]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['embed_A.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_test = '../data/QA_bAbI_tasks/en-10k/qa1_single-supporting-fact_test.txt'\n",
    "bAbI_test = bAbIDataset(path_test, train=False, vocab=bAbI_train.word2idx, return_masks=True)\n",
    "test_loader = bAbIDataLoader(dataset=bAbI_test, batch_size=32, shuffle=False, to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "막 training 끝마치고 나서 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy = 0\n",
    "for i, batch in enumerate(test_loader.load()):\n",
    "    stories, stories_masks, questions, _, answers, _ = batch\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        stories = [get_cuda(x) for x in stories]\n",
    "        stories_masks = [get_cuda(x) for x in stories_masks]\n",
    "        questions, answers = get_cuda(questions, answers)\n",
    "    \n",
    "    for story, mask, q, a in zip(stories, stories_masks, questions, answers):\n",
    "        model.zero_grad()\n",
    "        pred = model(story.unsqueeze(0), q.unsqueeze(0), stories_masks=mask.unsqueeze(0))\n",
    "        accuracy += torch.eq(torch.max(pred, 1)[1], a).data[0]\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy/len(bAbI_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이상한 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-1]))\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from model.bAbI_utils_loader import bAbIDataset, bAbIDataLoader\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = 0 if USE_CUDA else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class E2EMN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, n_hops=3, encoding_method='basic', temporal=True, \\\n",
    "                 use_cuda=False, max_story_len=None):\n",
    "        super(E2EMN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.n_hops = n_hops\n",
    "        self.encoding_method = encoding_method.lower()\n",
    "        self.te = temporal\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        # sharing matrix for k hops & and init to normal dist.\n",
    "        self.embed_A = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.embed_B = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.embed_C = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        \n",
    "        # TE: temporal encoding\n",
    "        if self.te:\n",
    "            assert max_story_len is not None, 'must have a fixed story_len, insert \"max_story_len\" as a number'\n",
    "            assert isinstance(max_story_len, int), '\"max_story_len\" must be a integer'\n",
    "            \n",
    "            self.embed_A_T = nn.Embedding(max_story_len+1, self.embed_size, padding_idx=0)\n",
    "            self.embed_C_T = nn.Embedding(max_story_len+1, self.embed_size, padding_idx=0)\n",
    "            if self.use_cuda:\n",
    "                self.embed_A_T = self.embed_A_T.cuda()\n",
    "                self.embed_C_T = self.embed_C_T.cuda()            \n",
    "            \n",
    "        self.linear = nn.Linear(embed_size, vocab_size)\n",
    "        self._weight_init()\n",
    "    \n",
    "    def _weight_init(self):\n",
    "        for x in [self.embed_A, self.embed_B, self.embed_C]:\n",
    "            nn.init.normal(x.weight, mean=0, std=0.1)\n",
    "        if self.te:\n",
    "            for x in [self.embed_A_T, self.embed_C_T]:\n",
    "                nn.init.normal(x.weight, mean=0, std=0.1)\n",
    "    \n",
    "    def _temporal_encoding_requirements(self, stories_masks):\n",
    "        # temporal encoding\n",
    "        if self.te:\n",
    "            story_len = stories_masks.size(1)\n",
    "            temp = stories_masks.eq(0).sum(2) # B, n : byte tensor\n",
    "            te_idx_matrix = Variable(torch.arange(1, story_len+1).repeat(temp.size(0)).view(temp.size()), \\\n",
    "                                     requires_grad=False).long()\n",
    "            if self.use_cuda:\n",
    "                te_idx_matrix = te_idx_matrix.cuda()\n",
    "            te_idx_matrix = te_idx_matrix * temp.ge(1).long() # B, n\n",
    "        else:\n",
    "            te_idx_matrix = None\n",
    "            \n",
    "        return te_idx_matrix\n",
    "\n",
    "            \n",
    "    def _pe_requirements(self, stories_masks):\n",
    "        if stories_masks is not None:\n",
    "            pe_word_lengths = stories_masks.eq(0).sum(2) # B, n : byte tensor\n",
    "        else:\n",
    "            pe_word_lengths = None\n",
    "        return pe_word_lengths\n",
    "    \n",
    "    def encoding2memory(self, embeded_x, word_length=None):\n",
    "        \"\"\"\n",
    "        embed_x: n, T_c, d\n",
    "        word_length: n\n",
    "        \"\"\"\n",
    "        if self.encoding_method == 'basic':\n",
    "            return embeded_x.sum(1) # n, d\n",
    "        \n",
    "        elif self.encoding_method == 'pe':\n",
    "            assert word_length is not None, 'insert stories_masks when forward'\n",
    "            \n",
    "            T_c, d = embeded_x.size()[1:]\n",
    "            j = Variable(torch.arange(1, T_c+1).unsqueeze(1).repeat(1, d), requires_grad=False)\n",
    "            k = Variable(torch.arange(1, d+1).unsqueeze(1).repeat(1, T_c).t(), requires_grad=False)\n",
    "            if self.use_cuda:\n",
    "                j, k = j.cuda(), k.cuda()\n",
    "                    \n",
    "            embeded_x_pe = []\n",
    "            for embed, J in zip(embeded_x, word_length.float()): # iteration of n size\n",
    "                # embed: T_c d\n",
    "                # J: scalar\n",
    "                if J.eq(0).data[0]: # all words are pad data, which means word_length = 0\n",
    "                    embeded_x_pe.append(embed)\n",
    "                else:\n",
    "                    l = (torch.ones_like(embed).float() - j/J) - (k/d)*(torch.ones_like(embed) - (2*j)/J)\n",
    "                    embed = embed * l\n",
    "                    embeded_x_pe.append(embed) # T_c, d\n",
    "            embeded_x_pe = torch.stack(embeded_x_pe) # n, T_c, d\n",
    "            return embeded_x_pe.sum(1) # n, d\n",
    "        \n",
    "        else:\n",
    "            assert True, 'insert encoding_method key value in the model, default is \"basic\".'\n",
    "        \n",
    "    def forward(self, stories, questions, stories_masks=None, questions_masks=None):\n",
    "        \"\"\"\n",
    "        stories, stories_masks: B, n, T_c\n",
    "        questions, questions_masks: B, T_q\n",
    "        \"\"\"\n",
    "        # init some requirements\n",
    "        te_idx_matrix = self._temporal_encoding_requirements(stories_masks)\n",
    "        pe_word_lengths = self._pe_requirements(stories_masks) # B, n \n",
    "        \n",
    "        # Start Learning\n",
    "        o_list = []\n",
    "        # questions: B, T_q\n",
    "        embeded_B = self.embed_B(questions) # B, T_q, d\n",
    "        u = embeded_B.sum(1) # u: B, d\n",
    "        o_list.append(u) # [(B, d)]\n",
    "        \n",
    "        for k in range(self.n_hops):\n",
    "            # encoding part: PE, TE\n",
    "            batch_memories = [] # B, n, d\n",
    "            batch_contexts = [] # B, n, d\n",
    "            for i, inputs in enumerate(stories): # iteration of batch\n",
    "                # inputs: n, T_c\n",
    "                embeded_A = self.embed_A(inputs) # n, T_c, d\n",
    "                embeded_C = self.embed_C(inputs)\n",
    "                # basic or PE\n",
    "                m = self.encoding2memory(embeded_A, pe_word_lengths[i]) # n, d\n",
    "                c = self.encoding2memory(embeded_C, pe_word_lengths[i]) # n, d\n",
    "                # TE\n",
    "                if self.te:\n",
    "                    A_T = self.embed_A_T(te_idx_matrix[i]) # n, d\n",
    "                    C_T = self.embed_C_T(te_idx_matrix[i]) # n, d\n",
    "                    m = m + A_T\n",
    "                    c = c + C_T\n",
    "                batch_memories.append(m)\n",
    "                batch_contexts.append(c)\n",
    "\n",
    "            batch_memories = torch.stack(batch_memories) # B, n, d\n",
    "            batch_contexts = torch.stack(batch_contexts) # B, n, d\n",
    "\n",
    "            # attention part: select which sentence to attent\n",
    "            # score = m * u[-1] : (B, n, d) * (B, d, 1) = B, n, 1\n",
    "            score = torch.bmm(batch_memories, o_list[-1].unsqueeze(2))\n",
    "            probs = F.softmax(score, dim=1) # p: B, n, 1\n",
    "\n",
    "            # output: element-wies mul & sum (B, n, d) x (B, n, 1) = B, n, d > B, d\n",
    "            o = torch.sum(batch_contexts * probs, 1)\n",
    "\n",
    "            o_next = o_list[-1] + o\n",
    "            o_list.append(o_next) # B, d\n",
    "        \n",
    "        # guessing part:\n",
    "        outputs = self.linear(o_list[-1]) # B, d > B, V\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_train = '../data/QA_bAbI_tasks/en-10k/qa1_single-supporting-fact_train.txt'\n",
    "bAbI_train = bAbIDataset(path_train, train=True, return_masks=True)\n",
    "train_loader = bAbIDataLoader(dataset=bAbI_train, batch_size=32, shuffle=True, to_tensor=True)\n",
    "VOCAB_SIZE = len(bAbI_train.word2idx)\n",
    "EMBED_SIZE = 50\n",
    "N_HOPS = 3\n",
    "LR = 0.01\n",
    "STEP = 100\n",
    "MAX_STORY_LEN = bAbI_train.max_story_len\n",
    "BATCH_SIZE = 32\n",
    "EARLY_STOPPING = False\n",
    "ENCODING_METHOD = 'pe'\n",
    "TEMPORAL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = '../model/E2EMN_te_pe.model'\n",
    "model = E2EMN(VOCAB_SIZE, EMBED_SIZE, n_hops=N_HOPS, encoding_method=ENCODING_METHOD, \n",
    "              temporal=TEMPORAL, use_cuda=USE_CUDA, max_story_len=MAX_STORY_LEN)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0395 -0.0858  0.0412  ...   0.1262  0.0139  0.0196\n",
       " 0.0534 -0.0255  0.0567  ...  -0.0792 -0.0984  0.0134\n",
       " 0.1134 -0.1136 -0.1169  ...   0.1976  0.2035  0.4299\n",
       "          ...             ⋱             ...          \n",
       " 0.1963 -0.1190  0.2865  ...   0.0464  0.0401 -0.1248\n",
       " 0.0379 -0.1616 -0.0564  ...  -0.0298 -0.0663  0.1711\n",
       "-1.2460 -0.8436 -0.4601  ...   0.9631  0.3113 -0.7624\n",
       "[torch.FloatTensor of size 22x50]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['embed_A.weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_test = '../data/QA_bAbI_tasks/en-10k/qa1_single-supporting-fact_test.txt'\n",
    "bAbI_test = bAbIDataset(path_test, train=False, vocab=bAbI_train.word2idx, return_masks=True)\n",
    "test_loader = bAbIDataLoader(dataset=bAbI_test, batch_size=32, shuffle=False, to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나갔다가 load state 하고 나온 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.058\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy = 0\n",
    "for i, batch in enumerate(test_loader.load()):\n",
    "    stories, stories_masks, questions, _, answers, _ = batch\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        stories = [get_cuda(x) for x in stories]\n",
    "        stories_masks = [get_cuda(x) for x in stories_masks]\n",
    "        questions, answers = get_cuda(questions, answers)\n",
    "    \n",
    "    for story, mask, q, a in zip(stories, stories_masks, questions, answers):\n",
    "        model.zero_grad()\n",
    "        pred = model(story.unsqueeze(0), q.unsqueeze(0), stories_masks=mask.unsqueeze(0))\n",
    "        accuracy += torch.eq(torch.max(pred, 1)[1], a).data[0]\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy/len(bAbI_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "밑어꺼는 무관"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* basic: 0.653\n",
    "* pe_te: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bAbI_test = bAbIDataset(path_test, train=False, vocab=bAbI_train.word2idx, return_masks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.choice(bAbI_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "story, q, a, s = bAbI_test.pad_to_story([random.choice(bAbI_test.data)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: random print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "story, q, a, s = bAbI_test.pad_to_story([random.choice(bAbI_test.data)], w2idx)\n",
    "model.zero_grad()\n",
    "pred = model(story[0].unsqueeze(0), q)\n",
    "pred_a = torch.max(pred, 1)[1]\n",
    "\n",
    "print(\"Facts : \")\n",
    "print('-'*45)\n",
    "print('\\n'.join([' '.join(list(map(lambda x: idx2w[x], f))) for f in story[0].data.tolist()]))\n",
    "print('-'*45)\n",
    "print(\"Question : \",' '.join(list(map(lambda x: idx2w[x], q.data.tolist()[0]))))\n",
    "print('-'*45)\n",
    "print(\"Answer : \",' '.join(list(map(lambda x: idx2w[x], a.squeeze(1).data.tolist()))))\n",
    "print(\"Prediction : \",' '.join(list(map(lambda x: idx2w[x], pred_a.data.tolist()))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
